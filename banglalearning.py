# -*- coding: utf-8 -*-
"""banglaLearning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CylHZVLBdCIGi0rcLU7_-8Qq5d44SlMy
"""

# Install required libraries
!pip install pandas gTTS pydub openpyxl

!apt-get install fonts-noto-core -y
!apt-get install fonts-noto-extra -y
!apt-get install fonts-noto-unhinted -y

from gtts import gTTS
from pydub import AudioSegment
import pandas as pd
import os

# ==== 1. Mount Google Drive ====
from google.colab import drive
drive.mount('/content/drive')

# ==== 2. File path ====
from google.colab import files
uploaded = files.upload()

file_path = '/content/drive/MyDrive/TTS/1.Basic bangla/1.Basic bangla.xlsx'
output_path = '1.Basic bangla.mp3'

uploaded_file = '1.Basic bangla.xlsx'  # replace with actual name if different
file_path = os.path.join('/content/drive/MyDrive/TTS/1.Basic bangla/', uploaded_file)
print("Full path to file:", file_path)

import os

# List all files in the current working directory
os.listdir('/content')

!find /content -name "*.xlsx"

import pandas as pd

file_path = '/content/1.Basic bangla.xlsx'
df = pd.read_excel(file_path)
print("Columns found:", df.columns.tolist())

# ==== optimal audio generator with duration tracking ====
from google.colab import files
import pandas as pd
from gtts import gTTS
from pydub import AudioSegment
import os
from io import BytesIO
from datetime import datetime

# ==== Parameters (your pauses) ====
pause_short = AudioSegment.silent(duration=400)    # short pause between repetitions
pause_long = AudioSegment.silent(duration=1000)    # pause after word/example block
pause_entry = AudioSegment.silent(duration=1500)   # pause between entries

# ==== Prepare combined audio ====
combined_audio = AudioSegment.silent(duration=500)  # small silence at start for safety

# ==== Output folder ====
output_dir = '/content/drive/MyDrive/TTS/1.Basic bangla'
os.makedirs(output_dir, exist_ok=True)
output_path = os.path.join(output_dir, f'1.Basic bangla.mp3')

# ==== Timing tracker ====
timing_records = []       # will store (row_index, start_sec, end_sec, duration_sec)
current_timestamp = 0.5   # initial silence (500ms) → 0.5 sec

for idx, row in df.iterrows():
    word = str(row['bangla']).strip()
    example = str(row['example_bangla']).strip()

    if not word or word.lower() == 'nan':
        continue

    # ---- Word triple ----
    tts_word = gTTS(text=word, lang='bn')
    fp_word = BytesIO()
    tts_word.write_to_fp(fp_word)
    fp_word.seek(0)
    word_seg = AudioSegment.from_file(fp_word, format="mp3")

    word_audio = AudioSegment.silent(duration=0)
    for _ in range(3):
        word_audio += word_seg + pause_short
    word_audio += pause_long

    # ---- Example triple ----
    tts_example = gTTS(text=example, lang='bn')
    fp_example = BytesIO()
    tts_example.write_to_fp(fp_example)
    fp_example.seek(0)
    example_seg = AudioSegment.from_file(fp_example, format="mp3")

    ex_audio = AudioSegment.silent(duration=0)
    for _ in range(3):
        ex_audio += example_seg + pause_short
    ex_audio += pause_long

    # ---- Combine ----
    row_audio = word_audio + ex_audio + pause_entry

    # ---- Record timing ----
    start_time = current_timestamp
    end_time = start_time + (len(row_audio) / 1000)
    duration = end_time - start_time

    timing_records.append({
        "row_index": idx,
        "start_sec": round(start_time, 3),
        "end_sec": round(end_time, 3),
        "duration_sec": round(duration, 3),
        "topic": row.get("topic", ""),
        "word": word,
        "example": example
    })

    # Update overall timestamp
    current_timestamp = end_time

    # Add to final audio
    combined_audio += row_audio

# ==== Export final audio ====
combined_audio.export(output_path, format="mp3")
print(f" Audio created at: {output_path}")

# ==== Save timing file ====
timing_df = pd.DataFrame(timing_records)
timing_csv = os.path.join(output_dir, "audio_timing_basic_bangla.csv")
timing_df.to_csv(timing_csv, index=False)

print(f" Timing table saved at: {timing_csv}")

"""# **expriement voice**"""

!pip install --upgrade google-cloud-texttospeech

from google.cloud import texttospeech

client = texttospeech.TextToSpeechClient()
print("TTS client authenticated successfully!")

# optimal video - fixed with audio timing - with english
# final - with english
import os
import pandas as pd
from PIL import Image, ImageDraw, ImageFont
from moviepy.editor import ImageClip, concatenate_videoclips, AudioFileClip
from pydub import AudioSegment

# ==== File paths ====
excel_file = '/content/drive/MyDrive/TTS/alphabets/alphabets.xlsx'
audio_file = '/content/drive/MyDrive/TTS/alphabets/alphabets.mp3'
output_video = '/content/drive/MyDrive/TTS/alphabets/alphabets_video.mp4'
timing_file = '/content/drive/MyDrive/TTS/alphabets/audio_timing_1.csv'

os.makedirs("/tmp/slides", exist_ok=True)

# ==== Video settings ====
video_size = (1280, 720)
bg_color = (255, 255, 255)

# ==== Fonts ====
bangla_font_path = "/usr/share/fonts/truetype/noto/NotoSansBengali-Regular.ttf"
latin_font_path = "/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf"

bangla_font_large = ImageFont.truetype(bangla_font_path, 60)
bangla_font_medium = ImageFont.truetype(bangla_font_path, 50)
latin_font_medium = ImageFont.truetype(latin_font_path, 50)
latin_font_small = ImageFont.truetype(latin_font_path, 40)

# ==== Load Excel & timing file ====
df = pd.read_excel(excel_file)
timing_df = pd.read_csv(timing_file)

# ==== Helper functions ====
def get_text_width(draw, text, font):
    bbox = draw.textbbox((0, 0), text, font=font)
    return bbox[2] - bbox[0]

def draw_multiline_center(draw, text, font, x_center, y_start, max_width_pixels, fill="black", line_spacing=10):
    words = text.split()
    lines = []
    current_line = ""
    for word in words:
        test_line = f"{current_line} {word}".strip()
        if get_text_width(draw, test_line, font) <= max_width_pixels:
            current_line = test_line
        else:
            lines.append(current_line)
            current_line = word
    lines.append(current_line)

    y = y_start
    for line in lines:
        line_width = get_text_width(draw, line, font)
        draw.text((x_center - line_width//2, y), line, font=font, fill=fill)
        y += font.size + line_spacing
    return y

# ==== Generate video slides ====
clips = []

for idx, row in df.iterrows():
    topic = str(row['topic'])
    bangla = str(row['bangla'])
    transliteration = str(row['transliteration'])
    english = str(row['english_meaning'])
    example_trans = str(row['example_transliteration'])
    example_b = str(row['example_bangla'])
    example_eng = str(row['example_english'])
    pos = str(row['pos'])

    # Create blank slide
    img = Image.new("RGB", video_size, color=bg_color)
    draw = ImageDraw.Draw(img)

    # ===== Topic =====
    draw.text((video_size[0]-10, 10), topic, font=latin_font_small, fill="darkblue", anchor="ra")

    # ===== Top section =====
    y_pos = 40
    y_pos = draw_multiline_center(draw, bangla, bangla_font_large, video_size[0]//2, y_pos,
                                  max_width_pixels=1100, fill="red", line_spacing=15)
    y_pos = draw_multiline_center(draw, transliteration, latin_font_medium, video_size[0]//2, y_pos,
                                  max_width_pixels=1100, fill="green", line_spacing=12)
    y_pos = draw_multiline_center(draw, english, latin_font_medium, video_size[0]//2, y_pos,
                                  max_width_pixels=1100, fill="black", line_spacing=12)

    # ===== Example section =====
    bottom_y = 450
    bottom_y = draw_multiline_center(draw, example_b, bangla_font_medium, video_size[0]//2, bottom_y,
                                    max_width_pixels=1100, fill="red", line_spacing=12)
    bottom_y = draw_multiline_center(draw, example_trans, latin_font_small, video_size[0]//2, bottom_y,
                                    max_width_pixels=1100, fill="green", line_spacing=10)
    draw_multiline_center(draw, example_eng, latin_font_small, video_size[0]//2, bottom_y,
                          max_width_pixels=1100, fill="blue", line_spacing=10)

    # ===== POS left-middle =====
    draw.text((10, video_size[1]//2), pos, font=latin_font_small, fill="purple", anchor="lm")

    # Save slide
    tmp_path = f"/tmp/slides/slide_{idx}.png"
    img.save(tmp_path)



    # ===== USE REAL AUDIO TIMING =====
    timing_df["row_index"] = timing_df["row_index"].astype(int)

    clip_duration = float(
        timing_df.loc[timing_df["row_index"] == idx, "duration_sec"].values[0]
    )



    clip = ImageClip(tmp_path).set_duration(clip_duration)
    clips.append(clip)


# ==== Concatenate slides ====
final_video = concatenate_videoclips(clips, method="compose")

# ==== Attach the original full audio ====
audio_clip = AudioFileClip(audio_file)
final_video = final_video.set_audio(audio_clip)

# ==== Export video ====
final_video.write_videofile(output_video, fps=10, codec="libx264", audio_codec="aac")

print(f" text video created at: {output_video}")

print("Excel rows:", len(df))
print("Timing rows:", len(timing_df))
print("Unique row_index:", timing_df["row_index"].unique()[:10])

# optimal video - fixed  with audio timing  - non-english

import os
import pandas as pd
from PIL import Image, ImageDraw, ImageFont
from moviepy.editor import ImageClip, concatenate_videoclips, AudioFileClip
from pydub import AudioSegment

# ==== File paths ====
excel_file = '/content/drive/MyDrive/TTS/alphabets/alphabets.xlsx'
audio_file = '/content/drive/MyDrive/TTS/alphabets/alphabets.mp3'
output_video = '/content/drive/MyDrive/TTS/alphabets/alphabets_video_non_english.mp4'
timing_file = '/content/drive/MyDrive/TTS/alphabets/audio_timing_1.csv'

os.makedirs("/tmp/slides", exist_ok=True)

# ==== Video settings ====
video_size = (1280, 720)
bg_color = (255, 255, 255)

# ==== Fonts ====
bangla_font_path = "/usr/share/fonts/truetype/noto/NotoSansBengali-Regular.ttf"
latin_font_path = "/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf"

bangla_font_large = ImageFont.truetype(bangla_font_path, 60)
bangla_font_medium = ImageFont.truetype(bangla_font_path, 50)
latin_font_medium = ImageFont.truetype(latin_font_path, 50)
latin_font_small = ImageFont.truetype(latin_font_path, 40)

# ==== Load Excel & timing file ====
df = pd.read_excel(excel_file)
timing_df = pd.read_csv(timing_file)

# ==== Helper functions ====
def get_text_width(draw, text, font):
    bbox = draw.textbbox((0, 0), text, font=font)
    return bbox[2] - bbox[0]

def draw_multiline_center(draw, text, font, x_center, y_start, max_width_pixels, fill="black", line_spacing=10):
    words = text.split()
    lines = []
    current_line = ""
    for word in words:
        test_line = f"{current_line} {word}".strip()
        if get_text_width(draw, test_line, font) <= max_width_pixels:
            current_line = test_line
        else:
            lines.append(current_line)
            current_line = word
    lines.append(current_line)

    y = y_start
    for line in lines:
        line_width = get_text_width(draw, line, font)
        draw.text((x_center - line_width//2, y), line, font=font, fill=fill)
        y += font.size + line_spacing
    return y

# ==== Generate video slides ====
clips = []

for idx, row in df.iterrows():
    topic = str(row['topic'])
    bangla = str(row['bangla'])
    transliteration = str(row['transliteration'])
    english = str(row['english_meaning'])
    example_trans = str(row['example_transliteration'])
    example_b = str(row['example_bangla'])
    example_eng = str(row['example_english'])
    pos = str(row['pos'])

    # Create blank slide
    img = Image.new("RGB", video_size, color=bg_color)
    draw = ImageDraw.Draw(img)

    # ===== Topic =====
    draw.text((video_size[0]-10, 10), topic, font=latin_font_small, fill="darkblue", anchor="ra")

    # ===== Top section =====
    y_pos = 40
    y_pos = draw_multiline_center(draw, bangla, bangla_font_large, video_size[0]//2, y_pos,
                                  max_width_pixels=1100, fill="red", line_spacing=15)
    y_pos = draw_multiline_center(draw, transliteration, latin_font_medium, video_size[0]//2, y_pos,
                                  max_width_pixels=1100, fill="green", line_spacing=12)


    # ===== Example section =====
    bottom_y = 450
    bottom_y = draw_multiline_center(draw, example_b, bangla_font_medium, video_size[0]//2, bottom_y,
                                    max_width_pixels=1100, fill="red", line_spacing=12)
    bottom_y = draw_multiline_center(draw, example_trans, latin_font_small, video_size[0]//2, bottom_y,
                                    max_width_pixels=1100, fill="green", line_spacing=10)


    # ===== POS left-middle =====
    draw.text((10, video_size[1]//2), pos, font=latin_font_small, fill="purple", anchor="lm")

    # Save slide
    tmp_path = f"/tmp/slides/slide_{idx}.png"
    img.save(tmp_path)

    # ===== USE REAL AUDIO TIMING =====
    clip_duration = float(
        timing_df.loc[timing_df["row_index"] == idx, "duration_sec"].values[0]
    )

    clip = ImageClip(tmp_path).set_duration(clip_duration)
    clips.append(clip)

# ==== Concatenate slides ====
final_video = concatenate_videoclips(clips, method="compose")

# ==== Attach the original full audio ====
audio_clip = AudioFileClip(audio_file)
final_video = final_video.set_audio(audio_clip)

# ==== Export video ====
final_video.write_videofile(output_video, fps=10, codec="libx264", audio_codec="aac")

print(f" text video created at: {output_video}")

"""# **split into smaller**"""

import os
import subprocess
import pandas as pd
import re
import shutil
import json

# ===== Paths =====
VIDEOS = {
    "english": "/content/drive/MyDrive/TTS/1.Basic bangla/1.Basic_bangla_video_english.mp4",
    "non_english": "/content/drive/MyDrive/TTS/1.Basic bangla/1.Basic_bangla_video_non_english.mp4"
}
TIMING_CSV = "/content/drive/MyDrive/TTS/1.Basic bangla/audio_timing_basic_bangla.csv"
OUTPUT_BASE = "/content/drive/MyDrive/TTS/1.Basic bangla/units_all"
os.makedirs(OUTPUT_BASE, exist_ok=True)

MAX_LEN = 300.0  # 5 minutes in seconds

# ===== Helper function =====
def slug(s):
    s = str(s).strip()
    s = re.sub(r"[^\w\s-]", "", s)
    s = re.sub(r"\s+", "_", s)
    return s[:80]

# ===== Load timing =====
df = pd.read_csv(TIMING_CSV).sort_values("start_sec").reset_index(drop=True)

# ===== Create 5-min chunks based on timing =====
def get_chunks(df, max_len=MAX_LEN):
    chunks = []
    cur_start = None
    cur_end = None
    cur_rows = []

    for _, r in df.iterrows():
        dur = float(r["duration_sec"])
        if cur_start is None:
            cur_start = float(r["start_sec"])
            cur_end = cur_start + dur
            cur_rows = [r]
            continue

        if (cur_end - cur_start) + dur <= max_len:
            cur_end += dur
            cur_rows.append(r)
        else:
            chunks.append((cur_start, cur_end, cur_rows))
            cur_start = float(r["start_sec"])
            cur_end = cur_start + dur
            cur_rows = [r]

    if cur_rows:
        chunks.append((cur_start, cur_end, cur_rows))
    return chunks

chunks = get_chunks(df)

# ===== Process each video version =====
for lang, video_path in VIDEOS.items():
    video_name = os.path.splitext(os.path.basename(video_path))[0]
    print(f"\nProcessing {lang} video: {video_name}")

    # Prepare temp output folders
    video_chunk_dir = os.path.join(OUTPUT_BASE, f"{lang}_video_chunks")
    audio_chunk_dir = os.path.join(OUTPUT_BASE, f"{lang}_audio_chunks")
    os.makedirs(video_chunk_dir, exist_ok=True)
    os.makedirs(audio_chunk_dir, exist_ok=True)

    # ===== Split video into 5-min chunks =====
    for i, (start, end, rows) in enumerate(chunks, 1):
        if len(rows) == 0:
            print(f"⚠ Skipping empty chunk {i} ({start:.2f}-{end:.2f}s)")
            continue  # skip empty chunk

        duration = end - start
        topics = pd.Series([r.get("topic", "") for r in rows]).dropna()
        if len(topics) == 0:
            title = f"Unit_{i:02d}"
        elif topics.nunique() == 1:
            title = topics.iloc[0]
        else:
            title = f"{topics.iloc[0]} → {topics.iloc[-1]}"
        fname_base = f"{i:02d}_{slug(title)}"

        # Video chunk filename with language
        video_file_name = f"{fname_base}_{lang}_video.mp4"
        video_out = os.path.join(video_chunk_dir, video_file_name)
        cmd = [
            "ffmpeg", "-y",
            "-ss", f"{start:.3f}",
            "-i", video_path,
            "-t", f"{duration:.3f}",
            "-c", "copy",
            video_out
        ]
        subprocess.run(cmd, check=True)

        # Audio chunk filename with language
        audio_file_name = f"{fname_base}_{lang}_audio.mp3"
        audio_out = os.path.join(audio_chunk_dir, audio_file_name)
        cmd_audio = [
            "ffmpeg", "-y",
            "-i", video_out,
            "-vn",               # no video
            "-ar", "44100",      # sampling rate
            "-ac", "2",          # stereo
            "-b:a", "192k",      # bitrate
            audio_out
        ]
        subprocess.run(cmd_audio, check=True)

        # ===== Create unit folder =====
        unit_folder = os.path.join(OUTPUT_BASE, f"Unit_{i:02d}_{slug(title)}_{lang}")
        os.makedirs(unit_folder, exist_ok=True)
        shutil.copy(video_out, os.path.join(unit_folder, video_file_name))
        shutil.copy(audio_out, os.path.join(unit_folder, audio_file_name))

        # ===== Create exercises folder & CSV =====
        exercises_folder = os.path.join(unit_folder, "exercises")
        os.makedirs(exercises_folder, exist_ok=True)

        # Create CSV with words in this unit
        rows_df = pd.DataFrame(rows)[["row_index", "topic", "word", "example"]]
        exercise_csv_path = os.path.join(exercises_folder, f"unit_{i:02d}_words.csv")
        rows_df.to_csv(exercise_csv_path, index=False, encoding="utf-8-sig")

        # ===== Metadata =====
        metadata = {
            "unit_number": i,
            "title": title,
            "language": lang,
            "video_file": video_file_name,
            "audio_file": audio_file_name,
            "exercises_file": f"exercises/unit_{i:02d}_words.csv",
            "start_sec": start,
            "end_sec": end,
            "duration_sec": duration
        }
        with open(os.path.join(unit_folder, "metadata.json"), "w", encoding="utf-8") as f:
            json.dump(metadata, f, indent=4, ensure_ascii=False)

print(f"\n All units created in: {OUTPUT_BASE}")

import os
import subprocess
import pandas as pd
import re
import shutil
import json

# ===== Paths =====
VIDEOS = {
    "english": "/content/drive/MyDrive/TTS/1.Basic bangla/1.Basic_bangla_video_english.mp4",
    "non_english": "/content/drive/MyDrive/TTS/1.Basic bangla/1.Basic_bangla_video_non_english.mp4"
}
TIMING_CSV = "/content/drive/MyDrive/TTS/1.Basic bangla/audio_timing_basic_bangla.csv"
EXCEL_FILE = "/content/1.Basic bangla.xlsx"
OUTPUT_BASE = "/content/drive/MyDrive/TTS/1.Basic bangla/units_all"
os.makedirs(OUTPUT_BASE, exist_ok=True)

MAX_LEN = 300.0  # 5 minutes in seconds

# ===== Helper function =====
def slug(s):
    s = str(s).strip()
    s = re.sub(r"[^\w\s-]", "", s)
    s = re.sub(r"\s+", "_", s)
    return s[:80]

# ===== Load timing & Excel =====
df_timing = pd.read_csv(TIMING_CSV)
df_excel = pd.read_excel(EXCEL_FILE).reset_index(drop=True)
df_full = pd.merge(df_timing, df_excel, left_on="row_index", right_index=True, how="left")
df_full = df_full.sort_values("start_sec").reset_index(drop=True)
df_full = df_full.rename(columns={"topic_y": "topic"})
if "topic_x" in df_full.columns:
    df_full = df_full.drop(columns=["topic_x"])

# ===== Split into 5-min chunks =====
def get_chunks(df, max_len=MAX_LEN):
    chunks = []
    cur_start = None
    cur_end = None
    cur_rows = []

    for _, r in df.iterrows():
        dur = float(r["duration_sec"])
        if cur_start is None:
            cur_start = float(r["start_sec"])
            cur_end = cur_start + dur
            cur_rows = [r]
            continue

        if (cur_end - cur_start) + dur <= max_len:
            cur_end += dur
            cur_rows.append(r)
        else:
            chunks.append((cur_start, cur_end, cur_rows))
            cur_start = float(r["start_sec"])
            cur_end = cur_start + dur
            cur_rows = [r]

    if cur_rows:
        chunks.append((cur_start, cur_end, cur_rows))
    return chunks

chunks = get_chunks(df_full)

# ===== Process each video version =====
for lang, video_path in VIDEOS.items():
    video_name = os.path.splitext(os.path.basename(video_path))[0]
    print(f"\nProcessing {lang} video: {video_name}")

    # Get total video length
    video_length = float(subprocess.check_output(
        ["ffprobe", "-i", video_path, "-show_entries", "format=duration",
         "-v", "quiet", "-of", "csv=p=0"]
    ))

    # Temp folders
    video_chunk_dir = os.path.join(OUTPUT_BASE, f"{lang}_video_chunks")
    audio_chunk_dir = os.path.join(OUTPUT_BASE, f"{lang}_audio_chunks")
    os.makedirs(video_chunk_dir, exist_ok=True)
    os.makedirs(audio_chunk_dir, exist_ok=True)

    for i, (start, end, rows) in enumerate(chunks, 1):
        if len(rows) == 0:
            print(f"⚠ Skipping empty chunk {i}")
            continue

        end = min(end, video_length)
        duration = end - start

        topics = pd.Series([r.get("topic", "") for r in rows]).dropna()
        if len(topics) == 0:
            title = f"Unit_{i:02d}"
        elif topics.nunique() == 1:
            title = topics.iloc[0]
        else:
            title = f"{topics.iloc[0]} → {topics.iloc[-1]}"

        fname_base = f"{i:02d}_{slug(title)}"

        # ===== Video chunk =====
        video_file_name = f"{fname_base}_{lang}_video.mp4"
        video_out = os.path.join(video_chunk_dir, video_file_name)
        cmd = [
            "ffmpeg", "-y",
            "-ss", f"{start:.3f}",
            "-i", video_path,
            "-t", f"{duration:.3f}",
            "-c", "copy",
            video_out
        ]
        try:
            subprocess.run(cmd, check=True, capture_output=True, text=True)
        except subprocess.CalledProcessError as e:
            print(f"⚠ Skipping video chunk {i}: ffmpeg error\n", e.stderr)
            continue

        # ===== Audio chunk =====
        audio_file_name = f"{fname_base}_{lang}_audio.mp3"
        audio_out = os.path.join(audio_chunk_dir, audio_file_name)
        cmd_audio = [
            "ffmpeg", "-y",
            "-i", video_out,
            "-vn",
            "-ar", "44100",
            "-ac", "2",
            "-b:a", "192k",
            audio_out
        ]
        try:
            subprocess.run(cmd_audio, check=True, capture_output=True, text=True)
        except subprocess.CalledProcessError as e:
            print(f"⚠ Skipping audio chunk {i}: ffmpeg error\n", e.stderr)
            continue

        # ===== Unit folder =====
        unit_folder = os.path.join(OUTPUT_BASE, f"Unit_{i:02d}_{slug(title)}_{lang}")
        os.makedirs(unit_folder, exist_ok=True)

        # Copy video/audio if they exist
        if os.path.exists(video_out):
            shutil.copy(video_out, os.path.join(unit_folder, video_file_name))
        else:
            print(f"⚠ Video chunk missing: {video_out}, skipping copy.")

        if os.path.exists(audio_out):
            shutil.copy(audio_out, os.path.join(unit_folder, audio_file_name))
        else:
            print(f"⚠ Audio chunk missing: {audio_out}, skipping copy.")


        # ===== Exercises CSV =====
        exercises_folder = os.path.join(unit_folder, "exercises")
        os.makedirs(exercises_folder, exist_ok=True)

        row_indices = [r["row_index"] for r in rows]
        rows_df = df_full[df_full["row_index"].isin(row_indices)]

        cols_to_keep = [
            "row_index", "topic", "bangla", "transliteration", "english_meaning",
            "example_bangla", "example_transliteration", "example_english", "pos"
        ]
        existing_cols = [c for c in cols_to_keep if c in rows_df.columns]
        rows_df = rows_df[existing_cols]

        exercise_csv_path = os.path.join(exercises_folder, f"unit_{i:02d}_words.csv")
        rows_df.to_csv(exercise_csv_path, index=False, encoding="utf-8-sig")

        # ===== Metadata =====
        metadata = {
            "unit_number": i,
            "title": title,
            "language": lang,
            "video_file": video_file_name,
            "audio_file": audio_file_name,
            "exercises_file": f"exercises/unit_{i:02d}_words.csv",
            "start_sec": start,
            "end_sec": end,
            "duration_sec": duration
        }
        with open(os.path.join(unit_folder, "metadata.json"), "w", encoding="utf-8") as f:
            json.dump(metadata, f, indent=4, ensure_ascii=False)

print(f"\n All units created in: {OUTPUT_BASE}")

import os
import subprocess
import pandas as pd
import re
import shutil
import json

# ===== Paths =====
VIDEOS = {
    "english": "/content/drive/MyDrive/TTS/1.Basic bangla/1.Basic_bangla_video_english.mp4",
    "non_english": "/content/drive/MyDrive/TTS/1.Basic bangla/1.Basic_bangla_video_non_english.mp4"
}
TIMING_CSV = "/content/drive/MyDrive/TTS/1.Basic bangla/audio_timing_basic_bangla.csv"
EXCEL_FILE = "/content/1.Basic bangla.xlsx"
OUTPUT_BASE = "/content/drive/MyDrive/TTS/1.Basic bangla/units_all"
os.makedirs(OUTPUT_BASE, exist_ok=True)

MAX_LEN = 300.0  # 5 minutes in seconds

# ===== Helper function =====
def slug(s):
    s = str(s).strip()
    s = re.sub(r"[^\w\s-]", "", s)
    s = re.sub(r"\s+", "_", s)
    return s[:80]

# ===== Load timing & Excel =====
df_timing = pd.read_csv(TIMING_CSV)
df_excel = pd.read_excel(EXCEL_FILE).reset_index(drop=True)
df_full = pd.merge(df_timing, df_excel, left_on="row_index", right_index=True, how="left")
df_full = df_full.rename(columns={"topic_y": "topic"})

# ===== Create 5-min chunks based on timing =====
def get_chunks(df, max_len=MAX_LEN):
    chunks = []
    cur_start = None
    cur_end = None
    cur_rows = []

    for _, r in df.iterrows():
        dur = float(r["duration_sec"])
        if cur_start is None:
            cur_start = float(r["start_sec"])
            cur_end = cur_start + dur
            cur_rows = [r]
            continue

        if (cur_end - cur_start) + dur <= max_len:
            cur_end += dur
            cur_rows.append(r)
        else:
            chunks.append((cur_start, cur_end, cur_rows))
            cur_start = float(r["start_sec"])
            cur_end = cur_start + dur
            cur_rows = [r]

    if cur_rows:
        chunks.append((cur_start, cur_end, cur_rows))
    return chunks

chunks = get_chunks(df_full)

# ===== Process each video version independently =====
for lang, video_path in VIDEOS.items():
    video_name = os.path.splitext(os.path.basename(video_path))[0]
    print(f"\nProcessing {lang} video: {video_name}")

    # Prepare chunk directories
    video_chunk_dir = os.path.join(OUTPUT_BASE, f"{lang}_video_chunks")
    audio_chunk_dir = os.path.join(OUTPUT_BASE, f"{lang}_audio_chunks")
    os.makedirs(video_chunk_dir, exist_ok=True)
    os.makedirs(audio_chunk_dir, exist_ok=True)

    # ===== Split video/audio into chunks =====
    for i, (start, end, rows) in enumerate(chunks, 1):
        if len(rows) == 0:
            print(f"⚠ Skipping empty chunk {i} ({start:.2f}-{end:.2f}s)")
            continue

        duration = end - start
        topics = pd.Series([r.get("topic", "") for r in rows]).dropna()
        if len(topics) == 0:
            title = f"Unit_{i:02d}"
        elif topics.nunique() == 1:
            title = topics.iloc[0]
        else:
            title = f"{topics.iloc[0]} → {topics.iloc[-1]}"

        fname_base = f"{i:02d}_{slug(title)}"

        # ===== Video chunk =====
        video_file_name = f"{fname_base}_{lang}_video.mp4"
        video_out = os.path.join(video_chunk_dir, video_file_name)
        try:
            subprocess.run([
                "ffmpeg", "-y",
                "-ss", f"{start:.3f}",
                "-i", video_path,
                "-t", f"{duration:.3f}",
                "-c", "copy",
                video_out
            ], check=True)
        except subprocess.CalledProcessError:
            print(f"⚠ Failed to create video chunk: {video_out}")
            continue

        # ===== Audio chunk =====
        audio_file_name = f"{fname_base}_{lang}_audio.mp3"
        audio_out = os.path.join(audio_chunk_dir, audio_file_name)
        try:
            subprocess.run([
                "ffmpeg", "-y",
                "-i", video_out,
                "-vn",
                "-ar", "44100",
                "-ac", "2",
                "-b:a", "192k",
                audio_out
            ], check=True)
        except subprocess.CalledProcessError:
            print(f" Failed to create audio chunk: {audio_out}")
            continue

        # ===== Create unit folder =====
        unit_folder = os.path.join(OUTPUT_BASE, f"Unit_{i:02d}_{slug(title)}_{lang}")
        os.makedirs(unit_folder, exist_ok=True)
        shutil.copy(video_out, os.path.join(unit_folder, video_file_name))
        shutil.copy(audio_out, os.path.join(unit_folder, audio_file_name))

        # ===== Create exercises CSV =====
        exercises_folder = os.path.join(unit_folder, "exercises")
        os.makedirs(exercises_folder, exist_ok=True)

        row_indices = [r["row_index"] for r in rows]
        rows_df = df_full[df_full["row_index"].isin(row_indices)]
        cols_to_keep = [
            "row_index", "topic", "bangla", "transliteration", "english_meaning",
            "example_bangla", "example_transliteration", "example_english", "pos"
        ]
        rows_df = rows_df[cols_to_keep]
        exercise_csv_path = os.path.join(exercises_folder, f"unit_{i:02d}_words.csv")
        rows_df.to_csv(exercise_csv_path, index=False, encoding="utf-8-sig")

        # ===== Save metadata =====
        metadata = {
            "unit_number": i,
            "title": title,
            "language": lang,
            "video_file": video_file_name,
            "audio_file": audio_file_name,
            "exercises_file": f"exercises/unit_{i:02d}_words.csv",
            "start_sec": start,
            "end_sec": end,
            "duration_sec": duration
        }
        with open(os.path.join(unit_folder, "metadata.json"), "w", encoding="utf-8") as f:
            json.dump(metadata, f, indent=4, ensure_ascii=False)

print(f"\n All units created in: {OUTPUT_BASE}")